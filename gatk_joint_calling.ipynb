{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# WGS GVCF samples joint calling, filtering and quality control \n",
    "\n",
    "Implementing a GATK + VCF_QC workflow in [SoS](https://github.com/vatlab/SOS), written by Isabelle Schrauwen with software containers built by Gao Wang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%revisions -s -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This SoS workflow notebook contains four workflows:\n",
    "\n",
    "- `gatk_call`\n",
    "- `gatk_filter_strict`\n",
    "- `gatk_filter_basic`\n",
    "- `vcf_qc`\n",
    "- `submit_csg`\n",
    "\n",
    "The first four workflows are for the analysis and the last one is for submitting jobs on the cluster.\n",
    "\n",
    "All workflow steps are numerically ordered to reflect the execution logic. This is the most straightforward SoS workflow style, the \"process-oriented\" style. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input data\n",
    "\n",
    "Samples in `GVCF` format, already indexed:\n",
    "\n",
    "```\n",
    "*.gvcf.gz\n",
    "*.gvcf.gz.tbi\n",
    "```\n",
    "\n",
    "To input the list of samples to the workflow, please include all sample file names you would like to analyze, in a text file. For example:\n",
    "\n",
    "```\n",
    "GH.AR.SAD.P1.001.0_X3547_S42_1180478_GVCF.hard-filtered.gvcf.gz\n",
    "GH.AR.SAD.P1.003.0_92455_S43_1189700_GVCF.hard-filtered.gvcf.gz\n",
    "GH.AR.SAD.P1.004.0_92456_S44_1189701_GVCF.hard-filtered.gvcf.gz\n",
    "GH.AR.SAD.P1.005.0_92457_S20_1189702_GVCF.hard-filtered.gvcf.gz\n",
    "...\n",
    "```\n",
    "\n",
    "and save it as, eg, `20200820_sample_manifest.txt`. This text file will be the input file to the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Reference data preparation\n",
    "\n",
    "Human genome reference files are needed for `GATK` joint calling; `ANNOVAR` database references are needed for `ANNOVAR` annotations.\n",
    "\n",
    "- `GATK` reference files include:\n",
    "\n",
    "```\n",
    "*.fa\n",
    "*.fa.fai\n",
    "*.dict\n",
    "```\n",
    "\n",
    "- `VCF_QC` provides quality control measurementes on the VCF such as sex checks, heterozygosity, and relatedness. \n",
    "\n",
    "This workflow assumes that the required files already exit. This pipeline does not provide steps to download or to generate them automatically, which you could find in the tutorial slides. The pipeline will indeed check the availability of the reference files and quit on error if they are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Run the workflow\n",
    "\n",
    "The workflow is currently designed to run on a Linux cluster (via `singularity`) although it can also be executed on a Mac computer\n",
    "(via `docker`). In brief, after installing [SoS](https://github.com/vatlab/SOS) (also see section \"Software Configuration\" below), \n",
    "you can choose to run different workflows modules.\n",
    "\n",
    "For example to run the variant calling workflow,\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb call \\\n",
    "    --vcf-prefix /path/to/some_vcf_file_prefix \\\n",
    "    --samples /path/to/list/of/sample_gvcf.txt \\\n",
    "    --samples-dir /path/to/sample_gvcf \\\n",
    "    --ref-genome /path/to/reference_genome.fa \\\n",
    "    ...\n",
    "```\n",
    "\n",
    "to run variant filtering both strict or basic, \n",
    "\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb filter_strict \\\n",
    "    --vcf-prefix /path/to/some_vcf_file_prefix \\\n",
    "    --cwd output \\\n",
    "    --variant_filter strict\n",
    "    ...\n",
    "```\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb filter_basic \\\n",
    "    --vcf-prefix /path/to/some_vcf_file_prefix \\\n",
    "    --cwd output \\\n",
    "    --variant_filter basic\n",
    "    ...\n",
    "```\n",
    "\n",
    "to run vcf_qc,\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb vcf_qc \\\n",
    "    --vcf-prefix /path/to/some_vcf_file_prefix \\\n",
    "    --cwd output \\\n",
    "    --variant_filter basic\n",
    "    ...\n",
    "```\n",
    "\n",
    "You can put all these 3 commands to one bash file and execute that, so you run all steps one after another.\n",
    "\n",
    "Note that `...` are additional options that fall into two categories:\n",
    "\n",
    "1. Options needed to run the bioinformatics steps (e.g. ref_genome)\n",
    "2. Options needed for SoS to run on different platforms ( e.g. container-option)\n",
    "\n",
    "To view all options,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run gatk_joint_calling.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  call\n",
      "  strict_filter\n",
      "  basic_filter\n",
      "  vcf_qc\n",
      "\n",
      "Global Workflow Options:\n",
      "  --vcf-prefix joint_call_output (as path)\n",
      "                        Combined VCF file prefix, including path to the output\n",
      "                        but without vcf.gz extension, eg\n",
      "                        \"/path/to/output_filename\".\n",
      "  --cwd VAL (as path, required)\n",
      "                        Working directory\n",
      "  --build hg19\n",
      "                        Human genome build\n",
      "  --vcf-filter strict\n",
      "                        VCF filtering strategy e.x: strict or basic (default is\n",
      "                        strict)\n",
      "  --mem 12 (as int)\n",
      "                        Memory allocated to a job, in terms of Gigabyte\n",
      "  --container-option 'gaow/gatk4-annovar'\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  call_1:               Combine GVCF files\n",
      "    Workflow Options:\n",
      "      --samples VAL (as path, required)\n",
      "                        A file listing out all sample GVCF you would like to\n",
      "                        analyze. Each line is one sample GVCF name.\n",
      "      --samples-dir . (as path)\n",
      "                        Directory where sample GVCF files locate.\n",
      "      --ref-genome refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa (as path)\n",
      "                        Path to reference genome file\n",
      "  call_2:               Joint calling\n",
      "    Workflow Options:\n",
      "      --ref-genome VAL (as path, required)\n",
      "                        Path to reference genome file\n",
      "  strict_filter_1:      Split into SNP and INDEL for separate PASS filters\n",
      "  strict_filter_2:      PASS or filter for indels and SNPs (Note | not\n",
      "                        recommended for filters) Ignore MQRankSum warnings <-\n",
      "                        can only be calculated for het sites (not homs)\n",
      "    Workflow Options:\n",
      "      --snp-filters QD < 2.0, QD2 QUAL < 30.0, QUAL30 SOR > 3.0, SOR3 FS > 60.0, FS60 MQ < 40.0, MQ40 MQRankSum < -12.5, MQRankSum-12.5 ReadPosRankSum < -8.0, ReadPosRankSum-8 (as list)\n",
      "      --indel-filters QD < 2.0, QD2 QUAL < 30.0, QUAL30 FS > 200.0, FS200 ReadPosRankSum < -20.0, ReadPosRankSum-20 (as list)\n",
      "  strict_filter_3:      Merge back SNP and INDEL\n",
      "  strict_filter_4:      remove non-PASS variants if wanted\n",
      "  basic_filter_1:       remove all coverage < 4x, strand bias and end of read\n",
      "                        bias\n",
      "    Workflow Options:\n",
      "      --ref-genome refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa (as path)\n",
      "                        Path to reference genome file\n",
      "      --variant-filter QUAL < 30.0 , QUAL30 FS > 200.0, FS200 ReadPosRankSum < -20.0, ReadPosRankSum-20 DP < 4, DP4 (as list)\n",
      "  basic_filter_2:       Remove non-PASS variants\n",
      "  vcf_qc_1:             QC VCF for relatedness\n",
      "  vcf_qc_2:             QC VCF for sex check\n",
      "  vcf_qc_3:             QC VCF for IBD\n",
      "  vcf_qc_4:             QC VCF for relatedness\n",
      "  vcf_qc_5:             QC VCF for homozygosity mapping\n"
     ]
    }
   ],
   "source": [
    "sos run gatk_joint_calling.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Please read these options carefully before you start running the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Minimal working example\n",
    "\n",
    "A minimal example data-set can be found on CSG cluster. The following commands use this data-set, although in practice you should change the paths to point to your own data of interest.\n",
    "\n",
    "Joint calling:\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb call \\\n",
    "    --container-option /mnt/mfs/statgen/containers/gatk4-annovar.sif \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --samples /mnt/mfs/statgen/data_private/gatk_joint_call_example/20200820_sample_manifest.txt \\\n",
    "    --samples-dir /mnt/mfs/statgen/data_private/gatk_joint_call_example/ \\\n",
    "    --ref-genome /mnt/mfs/statgen/isabelle/REF/refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa \\\n",
    "    --cwd output \\\n",
    "    --vcf_filter strict\n",
    "```\n",
    "\n",
    "Filtering with strict filters:\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb strict_filter \\\n",
    "    --container-option /mnt/mfs/statgen/containers/gatk4-annovar.sif \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --cwd output \\\n",
    "    --vcf_filter strict\n",
    "```\n",
    "\n",
    "Filtering with basic filters:\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb basic_filter \\\n",
    "    --container-option /mnt/mfs/statgen/containers/gatk4-annovar.sif \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --ref-genome /mnt/mfs/statgen/isabelle/REF/refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa\\\n",
    "    --cwd output \\\n",
    "    --vcf_filter strict\n",
    "```\n",
    "\n",
    "VCF quality control (sex checks, IBD, heterozygosity, etc):\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb vcf_qc \\\n",
    "    --container-option /mnt/mfs/statgen/containers/gatk4-annovar.sif \\\n",
    "    --vcf-prefix output/minimal_example.snp_indel.filter.PASS \\\n",
    "    --cwd output \\\n",
    "    --vcf_filter strict\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Share the workflow with people\n",
    "\n",
    "Use \n",
    "\n",
    "```\n",
    "sos convert gatk_joint_calling.ipynb gatk_joint_calling.html --template sos-cm-toc\n",
    "```\n",
    "\n",
    "to convert this workflow to an HTML file, then pass it around to others to read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Software configuration\n",
    "\n",
    "Instructions on SoS and docker installation can be found on [our CSG wiki](http://statgen.us/lab-wiki/orientation/jupyter-setup.html). \n",
    "The instructions works for both Mac and Linux, unless otherwise specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Combined VCF file prefix, including path to the output but without vcf.gz extension, \n",
    "# eg \"/path/to/output_filename\".\n",
    "parameter: vcf_prefix = path('joint_call_output')\n",
    "# Working directory\n",
    "parameter: cwd = path\n",
    "# Human genome build\n",
    "parameter: build = 'hg19'\n",
    "# VCF filtering strategy e.x: strict or basic (default is strict)\n",
    "parameter: vcf_filter = 'strict'\n",
    "# Memory allocated to a job, in terms of Gigabyte\n",
    "parameter: mem=12\n",
    "# Software container option\n",
    "parameter: container_option = 'gaow/gatk4-annovar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Joint variant calling from GVCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Combine GVCF files\n",
    "[call_1]\n",
    "# A file listing out all sample GVCF you would like to analyze. \n",
    "# Each line is one sample GVCF name.\n",
    "parameter: samples = path\n",
    "# Directory where sample GVCF files locate.\n",
    "parameter: samples_dir = path()\n",
    "# Path to reference genome file\n",
    "parameter: ref_genome = path('refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa')\n",
    "#\n",
    "fail_if(not samples.is_file(), msg = 'Need valid sample name list file input via ``--samples`` option!')\n",
    "import os\n",
    "sample_files = [f'{samples_dir}/{os.path.basename(x.strip())}' for x in open(samples).readlines()]\n",
    "for x in sample_files:\n",
    "    fail_if(not path(x).is_file(), msg = f'Cannot find file ``{x}``. Please use ``--samples-dir`` option to specify the directory for sample files.')\n",
    "    fail_if(not x.endswith('gvcf.gz'), msg = f'Input file ``{x}`` does not have ``.gvcf.gz`` extension.')\n",
    "fail_if(len(sample_files) == 0, msg = 'Need at least one input sample file!')\n",
    "fail_if(not ref_genome.is_file(), msg = f'Cannot find reference genome ``{ref_genome}``. Please use ``--ref-genome`` option to specify it.')\n",
    "fail_if(not path(f\"{ref_genome:a}.fai\").is_file(), msg = f'Cannot find reference genome index file ``{ref_genome}.fai``. Please make sure it exists.')\n",
    "fail_if(not path(f\"{ref_genome:an}.dict\").is_file(), msg = f'Cannot find reference genome dict file ``{ref_genome:n}.dict``. Please make sure it exists.')\n",
    "\n",
    "depends: system_resource(mem = f'{mem}G'), ref_genome\n",
    "input: sample_files\n",
    "output: f'{vcf_prefix:a}.combined.vcf.gz'\n",
    "\n",
    "bash: container=container_option, volumes=[f'{ref_genome:ad}:{ref_genome:ad}'], expand=\"${ }\", stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    ${'&&'.join([\"tabix -p vcf %s\" % x for x in _input if not path(x + '.tbi').is_file()])}\n",
    "    gatk --java-options \"-Xmx${mem}g\" CombineGVCFs \\\n",
    "        -R ${ref_genome} \\\n",
    "        ${' '.join(['--variant %s' % x for x in _input])} \\\n",
    "        -O ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Joint calling\n",
    "[call_2]\n",
    "# Path to reference genome file\n",
    "parameter: ref_genome = path\n",
    "output: f'{vcf_prefix:a}.vcf.gz'\n",
    "\n",
    "\n",
    "bash: container=container_option, volumes=[f'{ref_genome:ad}:{ref_genome:ad}'], expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options \"-Xmx${mem}g\" GenotypeGVCFs \\\n",
    "        -R ${ref_genome} \\\n",
    "        -V ${_input} \\\n",
    "        -O ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Variant filtering\n",
    "\n",
    "Since we have two types of variants SNP and Indels, the first two steps of the filter workflow pipeline process the two variant types in parallel, then merge them and do additional filtering wiht steps 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Strict filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Split into SNP and INDEL for separate PASS filters\n",
    "[strict_filter_1]\n",
    "variant_type = ['SNP', 'INDEL']\n",
    "input: f'{vcf_prefix:a}.vcf.gz', for_each='variant_type', concurrent = True\n",
    "output: f'{vcf_prefix:a}.{_variant_type.lower()}.vcf.gz'\n",
    "\n",
    "\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' SelectVariants \\\n",
    "        -V ${_input} \\\n",
    "        -select-type ${_variant_type} \\\n",
    "        -O ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# PASS or filter for indels and SNPs (Note | not recommended for filters)\n",
    "# Ignore MQRankSum warnings <- can only be calculated for het sites (not homs)\n",
    "[strict_filter_2]\n",
    "parameter: snp_filters = ['QD < 2.0, QD2', 'QUAL < 30.0, QUAL30', 'SOR > 3.0, SOR3', 'FS > 60.0, FS60', 'MQ < 40.0, MQ40', 'MQRankSum < -12.5, MQRankSum-12.5', 'ReadPosRankSum < -8.0, ReadPosRankSum-8']\n",
    "parameter: indel_filters = [\"QD < 2.0, QD2\", \"QUAL < 30.0, QUAL30\", \"FS > 200.0, FS200\", \"ReadPosRankSum < -20.0, ReadPosRankSum-20\"]\n",
    "input: paired_with = dict(filter_option=[snp_filters, indel_filters])\n",
    "output: f'{_input:nn}.filter.vcf.gz'\n",
    "\n",
    "\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' VariantFiltration \\\n",
    "        -V ${_input} \\\n",
    "        ${\" \".join(['-filter \"%s\" --filter-name \"%s\"' % tuple([y.strip() for y in x.split(',')]) for x in _input.filter_option])} \\\n",
    "        -O ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge back SNP and INDEL\n",
    "[strict_filter_3]\n",
    "input: group_by = 'all'\n",
    "output: f'{vcf_prefix:a}.snp_indel.filter.vcf.gz'\n",
    "\n",
    "\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' MergeVcfs \\\n",
    "     -I ${_input[0]} -I ${_input[1]} -O ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# remove non-PASS variants if wanted\n",
    "[strict_filter_4]\n",
    "output: strict_out= f'{vcf_prefix:a}.snp_indel.filter.strict_QC.PASS.vcf.gz'\n",
    "\n",
    "\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' SelectVariants \\\n",
    "        -V ${_input} -O ${_output} \\\n",
    "        --exclude-filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Basic filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# remove all coverage < 4x, strand bias and end of read bias\n",
    "[basic_filter_1]\n",
    "# Path to reference genome file\n",
    "parameter: ref_genome = path('refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa')\n",
    "parameter: variant_filter = ['QUAL < 30.0 , QUAL30', 'FS > 200.0, FS200', 'ReadPosRankSum < -20.0, ReadPosRankSum-20', 'DP < 4, DP4']\n",
    "input: f'{vcf_prefix:a}.vcf.gz'\n",
    "output: f'{_input:nn}.snp_indel.filter.basic_QC.vcf.gz'\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' VariantFiltration \\\n",
    "    -R ${ref_genome} \\\n",
    "    -V ${_input} \\\n",
    "    ${\" \".join(['-filter \"%s\" --filter-name \"%s\"' % tuple([y.strip() for y in x.split(',')]) for x in variant_filter])} \\\n",
    "    -O ${_output}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Remove non-PASS variants\n",
    "[basic_filter_2]\n",
    "output: basic_out=f'{_input:nn}.PASS.vcf.gz'\n",
    "\n",
    "bash: container=container_option, expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.out'\n",
    "    gatk --java-options '-Xmx${mem}g' SelectVariants \\\n",
    "        -V ${_input} -O ${_output} \\\n",
    "        --exclude-filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extra VCF QC filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# QC VCF for relatedness\n",
    "[vcf_qc_1 (check relatedness)]\n",
    "input: f\"{vcf_prefix:a}.snp_indel.filter.{vcf_filter}_QC.PASS.vcf.gz\" \n",
    "output: f'{cwd}/vcf_qc/{_input:bnn}.relatedness', f'{cwd}/vcf_qc/{_input:bnn}.relatedness2'\n",
    "bash: expand=\"${ }\", stderr=f'{cwd}/vcf_qc/{_output[0]:b}.err', stdout=f'{cwd}/vcf_qc/{_output[0]:b}.log'\n",
    "\n",
    "    vcftools --relatedness --gzvcf ${_input} --out ${_output[0]:n}\n",
    "    vcftools --relatedness2 --gzvcf ${_input} --out ${_output[1]:n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# QC VCF for sex check\n",
    "[vcf_qc_2 (check sex)]\n",
    "input: f\"{vcf_prefix:a}.snp_indel.filter.{vcf_filter}_QC.PASS.vcf.gz\"\n",
    "output: bed=f'{cwd}/vcf_qc/{_input:bnn}.bed'\n",
    "bash: expand=\"${ }\", stderr=f\"{_output:n}.sex.err\",stdout=f\"{_output:n}.sex.log\"\n",
    "    plink --vcf ${_input} --double-id --make-bed --out ${_output:n} --allow-extra-chr\n",
    "    plink --bfile ${_output:n} --check-sex --out ${_output:n}.sex --allow-extra-chr\n",
    "    plink --bfile ${_output:n} --check-sex 0.35 0.65 --out ${_output:n}.sex2 --allow-extra-chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# QC VCF for IBD\n",
    "[vcf_qc_3 (IBD)]\n",
    "input: output_from('vcf_qc_2')['bed']\n",
    "output: f'{_input:n}.IBD.genome',\n",
    "        f'{_input:n}.HET.het',\n",
    "        f'{_input:n}.IBC.ibc',\n",
    "        f'{_input:n}.SEX.2.C.sexcheck',\n",
    "        vcf=f'{_input:n}.C.VCF.vcf'\n",
    "bash: expand=\"${ }\", stderr=f'{_output[0]}.err', stdout=f'{_output[0]}.log'\n",
    "    #add plink IBD\n",
    "    #missing rate per SNP MAF and HWE cut-off\n",
    "    plink --bfile ${_input:n} --geno 0.1 --hwe 0.00001 --maf 0.05 --make-bed --out ${_input:n}.C --allow-extra-chr\n",
    "    #LD pruning with window size 100 step size 10 and r^2 threshold 0.5 (MAF <0.05)\n",
    "    plink --bfile ${_input:n}.C --indep-pairwise 50 5 0.5 --make-bed --out  ${_input:n}.CP --allow-extra-chr\n",
    "    #IBD sharing\n",
    "    plink --bfile ${_input:n}.CP --genome --make-bed --out ${_output[0]:n} --allow-extra-chr\n",
    "    #het (Inbreeding and absence of heterozygosity)\n",
    "    plink --bfile ${_input:n}.CP --het --make-bed --out ${_output[1]:n} --allow-extra-chr\n",
    "    #IBCs (Inbreeding coeff)\n",
    "    plink --bfile ${_input:n}.CP --ibc --make-bed --out ${_output[2]:n} --allow-extra-chr\n",
    "    ###cleaned sex\n",
    "    plink --bfile ${_input:n}.C --check-sex 0.35 0.65 --out ${_output[3]:n} --allow-extra-chr\n",
    "    ####cleaned relatedness\n",
    "    plink --bfile ${_input:n}.C --recode vcf --out ${_output[4]:n} --allow-extra-chr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# QC VCF for relatedness\n",
    "[vcf_qc_4 (vcftools)]\n",
    "input: named_output(\"vcf\")\n",
    "output: f'{_input:n}.C.relatedness', f'{_input:n}.C.2.relatedness2'\n",
    "bash: expand=\"${ }\", stderr=f'{_output[0]}.err', stdout=f'{_output[0]}.log'\n",
    "\n",
    "    bgzip ${_input} && tabix -p vcf ${_input}.gz\n",
    "    vcftools --relatedness --gzvcf ${_input}.gz --out ${_output[0]:n}\n",
    "    vcftools --relatedness2 --gzvcf ${_input}.gz --out ${_output[1]:n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# QC VCF for homozygosity mapping \n",
    "[vcf_qc_5 (homozygosity mapping)]\n",
    "parameter: vcf_filter = 'strict'\n",
    "input:  f\"{cwd}/vcf_qc/{vcf_prefix:b}.snp_indel.filter.{vcf_filter}_QC.PASS.bed\"\n",
    "output: f'{_input:n}.HOM.hom'\n",
    "bash: expand=\"${ }\", stderr=f'{_output:nn}.err', stdout=f'{_output:nn}.log'\n",
    "    ##hom_mapping per sample (at least 100 SNPs, and of total length ≥ 1000 (1Mb) - 0.01 MAF\n",
    "    plink --bfile ${_input:n} --geno 0.1 --hwe 0.00001 --maf 0.01 --make-bed --out ${_input:n}.CH --allow-extra-chr\n",
    "    plink --bfile ${_input:n}.CH --homozyg --make-bed --out ${_output:n} --allow-extra-chr\n",
    "    #remove all the unwanted files at the end\n",
    "    ##FIXME\n",
    "    mkdir ${cwd}/vcf_qc/cache\n",
    "    mv ${cwd}/vcf_qc/*.{bed,bim,fam,log,nosex,in,out,gz,tbi} ${cwd}/vcf_qc/cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Submit jobs to the cluster\n",
    "\n",
    "Suppose we would like to submit these lines of commands to the cluster:\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb call \\\n",
    "    --container-option /mnt/mfs/statgen/containers/gatk4-annovar.sif \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --samples /mnt/mfs/statgen/data_private/gatk_joint_call_example/20200820_sample_manifest.txt \\\n",
    "    --samples-dir /mnt/mfs/statgen/data_private/gatk_joint_call_example/ \\\n",
    "    --ref-genome /mnt/mfs/statgen/isabelle/REF/refs/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa\\\n",
    "    --cwd output/ \\ \n",
    "    --variant_filter 'strict'\n",
    "\n",
    "sos run gatk_joint_calling.ipynb strict_filter \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --cwd output/ \\\n",
    "    --variant_filter 'strict'\n",
    "    \n",
    "sos run gatk_joint_calling.ipynb basic_filter \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --cwd output/ \\\n",
    "    --variant_filter 'basic'\n",
    "\n",
    "sos run gatk_joint_calling.ipynb vcf_qc \\\n",
    "    --vcf-prefix output/minimal_example \\\n",
    "    --cwd output/ \\\n",
    "    --variant_filter 'basic'\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "First, we save the above lines to a text file, e.g. call it `analysis_commands_20200825.txt`, then use the following workflow steps to allocate resources and submit the jobs.\n",
    "\n",
    "Example to submit a job:\n",
    "\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb submit_csg \\\n",
    "    --cmd_file command_1027.txt \\\n",
    "    --cwd output\n",
    "    \n",
    "sos run ~/gatk_joint_calling_test.ipynb submit_csg \\\n",
    "    --cmd_file ~/gatk_joint_calling/command_1027.txt \\\n",
    "    --cwd output\n",
    "```\n",
    "\n",
    "\n",
    "If you want to run in a dryrun mode, meaning just simply test the process but do not genrate results\n",
    "```\n",
    "sos run gatk_joint_calling.ipynb submit_csg \\\n",
    "    --cmd_file analysis_commands_20200825.txt \\\n",
    "    --cwd output \\\n",
    "    --dryrun True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Job submission on CSG cluster\n",
    "[submit_csg]\n",
    "# Path to job file\n",
    "parameter: cmd_file=path\n",
    "# Total run time allocated to the script\n",
    "parameter: time='36:00:00'\n",
    "parameter: dryrun = False\n",
    "input: cmd_file\n",
    "python3: expand = '$[ ]'\n",
    "    tpl = '''\n",
    "    #!/bin/sh\n",
    "    #$ -l h_rt=$[time]\n",
    "    #$ -l h_vmem=$[mem+6]G\n",
    "    #$ -N gatk_joint_call\n",
    "    #$ -cwd\n",
    "    #$ -j y\n",
    "    #$ -S /bin/bash\n",
    "    module load Singularity\n",
    "    module load VCFTOOLS/0.1.17\n",
    "    module load PLINK/1.9.10 \n",
    "    export PATH=$HOME/miniconda3/bin:$PATH\n",
    "    set -e\n",
    "    '''\n",
    "    script = tpl.lstrip() + ''.join(open($[_input:r]).readlines())\n",
    "    exe = 'cat' if $[dryrun] else 'qsub'\n",
    "    from subprocess import Popen, PIPE\n",
    "    import sys\n",
    "    p = Popen(exe, shell = False, stdin = PIPE, stdout = PIPE, stderr = PIPE, close_fds = True)\n",
    "    for item in p.communicate(script.encode(sys.getdefaultencoding())):\n",
    "        output = item.decode(sys.getdefaultencoding()).rstrip()\n",
    "        if output:\n",
    "            print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
